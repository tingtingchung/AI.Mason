**Topic 09: Introduction to Language Models**  
[CH09-1: Featurizing Documents Digitally](https://www.dropbox.com/scl/fi/1nznya5ojltmgz9bipvny/M3-1-featurizing-documents-digitally.pptx?rlkey=xai73tovu307z9nciywwqnur2&dl=0)  
[CH09-2: Embeddings](https://www.dropbox.com/scl/fi/8aefnfuyaf3c5dbclqkhr/M3-2-embeddings.pptx?rlkey=z0uvv0k4dinm98p7zqbrzumxv&dl=0)  
[CH09-3: RNN + LSTM](https://www.dropbox.com/scl/fi/mwob6sy8zmirkoeasvdrz/M3-3-rnn.pptx?rlkey=o63ghlkx1x8ith7y6e0q19s3l&dl=0)  

**Demos**  
[Tiktokenizer](https://tiktokenizer.vercel.app/)  
[Small Language Model Demo](https://www.cs.cmu.edu/~pvirtue/AIS/ngrams/ngrams.html)  
[Tensorflow's Embedding Explorer](https://projector.tensorflow.org/)  

**Colabs**  
[Tokenization](https://colab.research.google.com/drive/1NBF7FufmuftfL9o-ZK0R0_hBzqEZTy3m?usp=drive_link)  
[RNN + LSTM](https://colab.research.google.com/drive/1CvH2EySGqu6tIde9Sl0TK8nqriBzOgbm?usp=drive_link)  

**Required Readings**  
[Chapter 10.4 & 10.5 Recurrent Neural Networks, ISLP](https://hastie.su.domains/ISLP/ISLP_website.pdf.download.html)  
[TF Word Embeddings](https://www.tensorflow.org/text/guide/word_embeddings)  
[TF Tokenizers](https://www.tensorflow.org/text/guide/tokenizers)  
[Keras Recurrent Layers](https://keras.io/api/layers/recurrent_layers/)  
[Keras Preprocessing Layers](https://keras.io/api/layers/preprocessing_layers/)  
[Keras TextVectorization Layer](https://keras.io/api/layers/preprocessing_layers/text/text_vectorization/)  
[Masking & Padding in Keras](https://www.tensorflow.org/guide/keras/masking_and_padding#:~:text=Padding%20is%20a%20special%20form,pad%20or%20truncate%20some%20sequences.)  

**Optional References**  
[Karpathy, A., Johnson, J., & Fei-Fei, L. (2015). Visualizing and understanding recurrent networks. arXiv preprint arXiv:1506.02078.](http://vision.stanford.edu/pdf/KarpathyICLR2016.pdf)   
[A Critical Review of Recurrent Neural Networks for Sequence Learning by Zack Lipton et al. 2015](https://arxiv.org/abs/1506.00019)  
[Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention is all you need. Advances in neural information processing systems, 30.](https://arxiv.org/abs/1706.03762)  
[Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)  
[Sparse Matrix Format in Tensorflow](https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor)  

*Optional Fun Stuff*  
[Real life example of matrix |An image is nothing but a matrix of pixel values.](https://www.youtube.com/watch?v=RDBWWZ7o5sQ)  
[Cats vs. Dogs? Lets Make an AI to Settle This by CrashCourse AI](https://www.pbs.org/video/cats-vs-dogs-lets-make-an-ai-to-settle-this-lab-19-rp1lwa/) 
[Natural Language Processing by CrashCourse AI](https://www.pbs.org/video/natural-language-processing-7-eroyod/)  
